---
title: "Digital Ocean"
---

import UpstashRedis from '/snippets/upstash-redis-aws-eks.mdx';
import MongoAtlas from '/snippets/mongo-atlas-section.mdx';
import EnvironmentVariables from '/snippets/environment-variables.mdx';

It's a step-by-step Ship deployment guide. We will use Digital Ocean Managed [Kubernetes](https://www.digitalocean.com/products/kubernetes), [Container Registry](https://www.digitalocean.com/products/container-registry), [Mongo Atlas](https://www.mongodb.com/), [GitHub Actions](https://github.com/features/actions) for automated deployment, and [CloudFlare](https://www.cloudflare.com/) for DNS and SSL configuration.

You need to create [GitHub](https://github.com/), [CloudFlare](https://www.cloudflare.com/), [Digital Ocean](https://www.digitalocean.com/) and [MongoDB Atlas](https://www.mongodb.com/cloud/atlas/register) accounts and install the next tools on your machine before starting:

* [kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl) - CLI tool for accessing Kubernetes cluster;
* [kubectx](https://github.com/ahmetb/kubectx) - CLI tool for easier switching between Kubernetes contexts;
* [helm](https://helm.sh/docs/intro/install) - CLI tool for managing Kubernetes deployments;
* [k8sec](https://github.com/dtan4/k8sec) - CLI tool for managing Kubernetes Secrets easily;

<Accordion title="How to install k8sec on Linux?">
  Download k8sec tar.gz, then do:

  ```
  chmod +x k8sec
  ```
  ```
  sudo cp k8sec /usr/local/bin/
  ```
  ```
  k8sec --help
  ```
</Accordion>

Try the next commands to ensure that everything is installed correctly:

```
kubectl

kubectx

helm

k8sec
```

Also, you need [git](https://git-scm.com/) and [Node.js](https://nodejs.org/en/) if you already haven't.

## Setup project

First, initialize your project. Type `npx create-ship-app@latest` in the terminal then choose **Digital Ocean Managed Kubernetes** deployment type.

![Init project](/images/init-project.png)

You will have next project structure.

```shell
/my-ship-app
  /.github
  /apps
    /api
    /web
  /deploy
  ...
```

## Container registry

You need to create [Container Registry](https://www.digitalocean.com/products/container-registry) for storing Docker images. The deployment script will upload images to Container Registry during the build step, and Kubernetes will automatically pull these images from Container Registry to run a new version of service during the deployment step.

Name container registry as the name of organization, which usually is equals to the name of the project: `my-ship-app`.

![Container Registry creation](/images/container-registry-creation.png)

After some time, you will get registry endpoint.

![Container Registry creation](/images/container-registry-created.png)

`registry.digitalocean.com/my-ship-app` is registry endpoint, where `my-ship-app` is registry name.

Docker images for each service are stored in separate repository.
In Digital Ocean repositories are created automatically when something is uploaded by specific paths.
During deployment process script will automatically create paths to repositories in next format:

- [**API**](/api-reference/overview) - registry.digitalocean.com/my-ship-app/api;
- [**Scheduler**](/scheduler) - registry.digitalocean.com/my-ship-app/scheduler;
- [**Migrator**](/migrator) - registry.digitalocean.com/my-ship-app/migrator;
- [**Web**](/web/overview) - registry.digitalocean.com/my-ship-app/web;

<Tip>
  Images for all environments will be uploaded to the same repository for each
  service.
</Tip>

## Kubernetes cluster

Now let's create [Managed Kubernetes](https://www.digitalocean.com/products/kubernetes) cluster.

<Steps>
  <Step title="Select a region">
    Navigate to the cluster creation page [here](https://cloud.digitalocean.com/kubernetes/clusters/new)<br/>
    <Tip>
      We recommend you to create a cluster in the region where your end-users are located, it will reduce response time to incoming requests to all services.
    </Tip>

    <Tip>
      Also, if your cluster will be located in one region with a Container Registry deployment process will be faster. You can find more information about regions [here](https://docs.digitalocean.com/products/platform/availability-matrix/).
    </Tip>
    <Frame>
      <img src="/images/cluster-region.png" alt="Cluster Region" />
    </Frame>
  </Step>

  <Step title="Set Node pool name">
    Set Node pool name (e.g. `pool-app`) and configure Nodes.
    Digital Ocean recommends creating at least 2 nodes for the production environment. These settings will have an impact on the price of the cluster.

    <Frame>
      <img src="/images/cluster-capacity.png" alt="Cluster Capacity" />
    </Frame>
  </Step>

  <Step title="Set cluster name">
    Set cluster name (e.g. `my-ship-app`). A common practice is to use the project name for it.

    <Frame>
      <img src="/images/cluster-name.png" alt="Cluster Name" />
    </Frame>
  </Step>

  <Step title="Review and Create">
    Click on `Create Kubernetes Cluster` button to create a cluster and wait for cluster to be ready.
  </Step>

  <Step title="Integrate with created Container Registry">
    After cluster is created, go to the Container Registry's settings and find `DigitalOcean Kubernetes integration` section.

    <Frame>
      <img src="/images/do/registry-settings.png" alt="Registry Settings" />
    </Frame>

    You need to select your newly created `my-ship-app` cluster.

    <Frame>
      <img src="/images/do/registry-check-cluster.png" alt="Registry Check Cluster" />
    </Frame>
  </Step>
</Steps>

## Personal access token

To upload docker images in Container Registry and pull them after from cluster we need Digital Ocean [Personal Access Token](https://cloud.digitalocean.com/account/api/tokens).
When you created cluster - one with **Read Only** scope was automatically created.

But we need to [generate](https://cloud.digitalocean.com/account/api/tokens/new) a new one with:

- Name (e.g. `my-ship-app-admin-deploy`)
- **Full Access** scope
- No expiration

<Tip>
  You cannot change scope of already generated token.
</Tip>

![Digital Ocean Token](/images/do-token.png)

We will need this token soon, so don't close this page yet.

![Digital Ocean Token](/images/do/full-access-token.png)

<Warning>
  Be very careful with Personal Access Token, if someone steals it he will get access
  to all resources from your Digital Ocean account.
</Warning>

## Accessing cluster from a local machine

<Steps>
  <Step title="Download cluster's kubeconfig">
    Download cluster's kubeconfig, this file includes information for accessing cluster through `kubectl`.

    <Frame>
      <img src="/images/kubeconfig-download.png" alt="Kubeconfig Download" />
    </Frame>

    <Accordion title="Expected structure of downloaded kubeconfig">
      ```yaml my-ship-app-kubeconfig.yaml
      apiVersion: v1
      clusters:
      - cluster:
          certificate-authority-data: ...
          server: https://...
        name: do-nyc3-my-ship-app
      contexts:
      - context:
          cluster: do-nyc3-my-ship-app
          user: do-nyc3-my-ship-app-admin
        name: do-nyc3-my-ship-app
      current-context: do-nyc3-my-ship-app
      kind: Config
      preferences: {}
      users:
      - name: do-nyc3-my-ship-app-admin
        user:
          token: dop_v1_...
      ```
    </Accordion>

    And replace initial **Read only** token with new **Full access** token from [Personal access token](#personal-access-token) section.

    ```yaml my-ship-app-kubeconfig.yaml {18-19}
    apiVersion: v1
    clusters:
    - cluster:
        certificate-authority-data: ...
        server: https://...
      name: do-nyc3-my-ship-app
    contexts:
    - context:
        cluster: do-nyc3-my-ship-app
        user: do-nyc3-my-ship-app-admin
      name: do-nyc3-my-ship-app
    current-context: do-nyc3-my-ship-app
    kind: Config
    preferences: {}
    users:
    - name: do-nyc3-my-ship-app-admin
      user:
        # replace this token for full access token
        token: dop_v1_...
    ```
  </Step>

  <Step title="Add cluster, context and user to kubeconfig">
    <Tip>
      [Kubeconfig](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/) files contain information about several clusters, you have your own on the local machine, it should have been created after `kubectl` installation.
    </Tip>

    You need to add information about the new cluster to your kubeconfig.
    Find `.kube/config` file on your machine, and add `cluster`, `context` and `user` values from `my-ship-app-kubeconfig.yaml`.

    ```yaml ~/.kube/config {7-11, 17-21, 29-33}
    apiVersion: v1
    clusters:
    - cluster:
        certificate-authority-data: ...
        server: https://...
      name: some-cluster
    # your new cluster from my-ship-app-kubeconfig.yaml goes here
    - cluster:
        certificate-authority-data: ...
        server: https://...
      name: do-nyc3-my-ship-app
    contexts:
    - context:
        cluster: some-cluster
        user: some-user
      name: some-cluster
    # your new context from my-ship-app-kubeconfig.yaml goes here
    - context:
        cluster: do-nyc3-my-ship-app
        user: do-nyc3-my-ship-app-admin
      name: do-nyc3-my-ship-app
    current-context: some-cluster
    kind: Config
    preferences: {}
    users:
    - name: some-user
      user:
        token: dop_v1_...
    # your new user from my-ship-app-kubeconfig.yaml goes here
    - name: do-nyc3-my-ship-app-admin
      user:
        token: dop_v1_...
    ```
  </Step>

  <Step title="Switch to cluster context">
    Execute kubectx in your terminal and select your cluster from the list.
    ```shell
    kubectx
    ```

    You will see the list of available clusters.

    ```shell
    some-cluster
    do-nyc3-my-ship-app
    ```

    Select your cluster from the list:
    ```shell
    kubectx do-nyc3-my-ship-app
    ```
  </Step>

  <Step title="Verify cluster access">
    Check the installed pods by running:

    ```shell
    kubectl get pods -A
    ```

    You should see a list of system pods in your cluster:

    ```shell
    NAMESPACE     NAME                            READY   STATUS    RESTARTS   AGE
    kube-system   cilium-tb8td                    1/1     Running   0          18m
    kube-system   cilium-x5w8n                    1/1     Running   0          19m
    kube-system   coredns-5679ffb5c8-b7dzj        1/1     Running   0          17m
    kube-system   coredns-5679ffb5c8-d465r        1/1     Running   0          17m
    kube-system   cpc-bridge-proxy-ebpf-2gzfr     1/1     Running   0          17m
    kube-system   cpc-bridge-proxy-ebpf-jknzh     1/1     Running   0          17m
    kube-system   csi-do-node-jcqd2               2/2     Running   0          17m
    kube-system   csi-do-node-rpx6q               2/2     Running   0          17m
    kube-system   do-node-agent-ldhxq             1/1     Running   0          17m
    kube-system   do-node-agent-pdksz             1/1     Running   0          17m
    kube-system   hubble-relay-66f54dcd57-l7xjb   1/1     Running   0          21m
    kube-system   hubble-ui-785bdbc45b-6xd57      2/2     Running   0          18m
    kube-system   konnectivity-agent-h79mt        1/1     Running   0          17m
    kube-system   konnectivity-agent-hvv67        1/1     Running   0          17m
    ```
  </Step>
</Steps>

## Ingress NGINX Controller

[ingress-nginx](https://github.com/kubernetes/ingress-nginx) is an Ingress controller for Kubernetes using [NGINX](https://nginx.org) as a reverse proxy and load balancer.

<Tip>
  Learn more about ingress-nginx functionality in the **[official documentation](https://docs.nginx.com/nginx-ingress-controller/intro/how-nginx-ingress-controller-works/)**.
</Tip>

<Steps>
  <Step title="Navigate to dependencies directory">
    Change to the `deploy/dependencies` directory in your terminal.
  </Step>

  <Step title="Configure Helm Values (Optional)">

    This step is required **only if** you specified a custom node pool name in your Digital Ocean Kubernetes cluster.

    If you did, update the `doks.digitalocean.com/node-pool` value in `values.yaml.gotmpl`:

    ```yaml deploy/dependencies/ingress-nginx/values.yaml.gotmpl {5}
    controller:
      publishService:
        enabled: true
      nodeSelector:
        doks.digitalocean.com/node-pool: pool-app

    rbac:
      create: true

    defaultBackend:
      enabled: false
    ```
  </Step>


  <Step title="Install dependencies">
    Install helm dependencies using helmfile:

    ```bash
    helmfile deps
    ```
  </Step>

  <Step title="Review and apply changes">
    Preview the changes first:

    ```bash
    helmfile diff
    ```

    If the preview looks correct, apply the configuration:

    ```bash
    helmfile apply
    ```
  </Step>
</Steps>

## DNS and SSL

<Steps>
  <Step title="Get Load Balancer Address">
    After deploying ingress-nginx, retrieve the Load Balancer's external ip:

    ```bash
    kubectl get svc ingress-nginx-controller -n ingress-nginx
    ```

    Copy the value from the `EXTERNAL-IP` column.

    ```shell
    NAME                       TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE
    ingress-nginx-controller   LoadBalancer   10.245.201.160   138.68.124.241   80:30186/TCP,443:32656/TCP   28m
    ```

    <Tip>
      It take some time while **ingress-nginx** will configure everything and
      provide `EXTERNAL-IP`.
    </Tip>
  </Step>

  <Step title="Domain Naming Convention">
    You can follow this recommended naming pattern for different environments:

    | Environment | API Domain           | Web Domain           |
    |-------------|----------------------|----------------------|
    | Production  | api.ship.com         | app.ship.com         |
    | Staging     | api.staging.ship.com | app.staging.ship.com |
  </Step>

  <Step title="Configure DNS in Cloudflare">
    1. First, ensure you have a domain in Cloudflare. You can either:
    - [Register a new domain](https://developers.cloudflare.com/registrar/get-started/register-domain/)
    - [Transfer an existing domain](https://developers.cloudflare.com/registrar/get-started/transfer-domain-to-cloudflare/)

    2. In the Cloudflare DNS tab, create 2 `A` records:
    - One for Web interface
    - One for API endpoint

    Both should point to your Load Balancer's external hostname.

    Enable the **Proxied** option to:
    - Route traffic through Cloudflare
    - Generate SSL certificates automatically

    <Frame>
      <img src="/images/do/cloudflare-api.png" alt="CloudFlare API DNS Configuration" />
    </Frame>

    <br/>

    <Frame>
      <img src="/images/do/cloudflare-web.png" alt="CloudFlare Web DNS Configuration" />
    </Frame>

    <Note>
      Cloudflare's free Universal SSL certificates only cover the apex domain and one subdomain level. For multiple subdomain levels, you'll need an [Advanced Certificate](https://developers.cloudflare.com/ssl/edge-certificates/advanced-certificate-manager/manage-certificates/).
    </Note>
  </Step>

  <Step title="Update Configuration Files">
    Update your domain settings in the appropriate environment configuration files:

    For API service:
    <CodeGroup>
      ```yaml deploy/app/api/production.yaml
      service: api
      port: 3001
      domain: api.my-ship-app.paralect.com
      ```

      ```yaml deploy/app/api/staging.yaml
      service: api
      port: 3001
      domain: api.my-ship-app.staging.paralect.com
      ```
    </CodeGroup>

    For Web service:
    <CodeGroup>
      ```yaml deploy/app/web/production.yaml
      service: web
      port: 3002
      domain: my-ship-app.paralect.com
      ```

      ```yaml deploy/app/web/staging.yaml
      service: web
      port: 3002
      domain: my-ship-app.staging.paralect.com
      ```
    </CodeGroup>
  </Step>
</Steps>

## MongoDB Atlas
<MongoAtlas provider="do" />

# Environment variables
<EnvironmentVariables />


## Setting up GitHub Actions CI/CD

To automate deployment through Github Actions you need to configure [Github Secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets) inside workflow files.

### Configuring GitHub Actions secrets and variables

<Note>
  Before starting, make sure you have created a GitHub repository for your project.
</Note>

GitHub Secrets and variables allow you to manage reusable configuration data.

Secrets are encrypted and are used for sensitive data. [Learn more about encrypted secrets](https://docs.github.com/actions/automating-your-workflow-with-github-actions/creating-and-using-encrypted-secrets).

Variables are shown as plain text and are used for non-sensitive data. [Learn more about variables](https://docs.github.com/actions/learn-github-actions/variables).

<Tip>
The deployment will be triggered on each commit:
- Commits to **main** branch → deploy to **staging** environment
- Commits to **production** branch → deploy to **production** environment
</Tip>

[Configure](https://docs.github.com/en/actions/security-for-github-actions/security-guides/using-secrets-in-github-actions#creating-secrets-for-a-repository) the following secrets and variables in your GitHub repository:

| Name                    | Type     | Description                                                                                                                 |
|-------------------------|----------|-----------------------------------------------------------------------------------------------------------------------------|
| DO_PERSONAL_ACCESS_TOKEN| secret   | The secret access user created for CI/CD. This allows GitHub Actions to authenticate with DO services                       |
| CLUSTER_NAME_STAGING    | variable | Name of the staging cluster. (our case: `my-ship-app`)                                                                      |
| CLUSTER_NAME_PRODUCTION | variable | Name of the production cluster. (our case: `my-ship-app`, same as staging cluster since we have only one cluster)           |
| CLUSTER_NODE_POOL       | variable | Name of the node pool. (our case: `pool-app`)                                                                               |
| REGISTRY_NAME           | variable | Name of the Digital Ocean Container Registry. (our case: `my-ship-app`)                                                    |

<Warning>
Never commit sensitive credentials directly to your repository. <br/>
  Always use GitHub Secrets for sensitive information like DO keys.
</Warning>

<Note>
Variables (unlike secrets) are visible in logs and can be used for non-sensitive configuration values that may need to be referenced or modified.
</Note>

<Note>
  We set up **DO_PERSONAL_ACCESS_TOKEN** to be universal for both production and staging environments with **Full access** scope.
</Note>

<Note>
  Your **KUBE_CONFIG_PRODUCTION** and **KUBE_CONFIG_STAGING** will be the same if you have only one cluster for both environments.
</Note>

<Frame>
  <img src="/images/do/gh-secrets.png" alt="GitHub Secrets" />
</Frame>

<Frame>
  <img src="/images/do/gh-variables.png" alt="GitHub Variables" />
</Frame>


Now commit all changes to GitHub that will trigger deployment, or you can [run a workflow manually](https://docs.github.com/en/actions/managing-workflow-runs-and-deployments/managing-workflow-runs/manually-running-a-workflow)

<Frame>
  <img src="/images/do/ci-start.png" alt="CI start" />
</Frame>

Done! Application deployed and can be accessed by the provided domain.


<Frame>
  <img src="/images/do/ci-finish.png" alt="CI finish" />
</Frame>


<Frame>
  <img src="/images/do/deployment-finish.png" alt="Deployment finish" />
</Frame>


```shell
kubectl get pods -A

NAMESPACE       NAME                                        READY   STATUS      RESTARTS   AGE
ingress-nginx   ingress-nginx-controller-6bdff8c8fd-kwxcn   1/1     Running     0          6h50m
kube-system     cilium-tb8td                                1/1     Running     0          8h
kube-system     cilium-x5w8n                                1/1     Running     0          8h
kube-system     coredns-5679ffb5c8-b7dzj                    1/1     Running     0          8h
kube-system     coredns-5679ffb5c8-d465r                    1/1     Running     0          8h
kube-system     cpc-bridge-proxy-ebpf-2gzfr                 1/1     Running     0          8h
kube-system     cpc-bridge-proxy-ebpf-jknzh                 1/1     Running     0          8h
kube-system     csi-do-node-jcqd2                           2/2     Running     0          8h
kube-system     csi-do-node-rpx6q                           2/2     Running     0          8h
kube-system     do-node-agent-ldhxq                         1/1     Running     0          8h
kube-system     do-node-agent-pdksz                         1/1     Running     0          8h
kube-system     hubble-relay-66f54dcd57-l7xjb               1/1     Running     0          8h
kube-system     hubble-ui-785bdbc45b-6xd57                  2/2     Running     0          8h
kube-system     konnectivity-agent-h79mt                    1/1     Running     0          8h
kube-system     konnectivity-agent-hvv67                    1/1     Running     0          8h
production      api-57d7787d98-cj75s                        1/1     Running     0          2m15s
production      migrator-286bq                              0/1     Completed   0          2m54s
production      scheduler-6c497dfbcc-n6b5l                  1/1     Running     0          2m6s
production      web-54c6674974-lv94b                        1/1     Running     0          71m
redis           redis-master-0                              1/1     Running     0          6h49m
staging         api-689b75c786-97c4l                        1/1     Running     0          71m
staging         scheduler-57b984f6c-zcc44                   1/1     Running     0          71m
staging         web-55bdd955b-chswp                         1/1     Running     0          70m
```

<Tip>
If something went wrong you can check the workflows logs on GitHub and use [**kubectl logs**](https://kubernetes.io/docs/reference/kubectl/cheatsheet/#interacting-with-running-pods), [**kubectl describe**](https://kubernetes.io/docs/reference/kubectl/cheatsheet/#viewing-finding-resources) commands.
</Tip>

## Setting up Upstash Redis database (recommended)
<UpstashRedis provider="do" />
